<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.17" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="//fonts.googleapis.com/css?family=Roboto:400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<link rel="stylesheet" href="/css/normalize.css">
<link rel="stylesheet" href="/css/skeleton.css">
<link rel="stylesheet" href="/css/custom.css">
<link rel="alternate" href="/index.xml" type="application/rss+xml" title="Patrick Oyarzun">
<title>Benchmarking (Benchmarking Elm Functions) - Patrick Oyarzun</title>
</head>
<body>

<div class="container">

	<header role="banner">
		<div class="header-logo">
			<a href="/"><img src="https://www.gravatar.com/avatar/1bd0f98dad76d9b2f7efc49a984f69aa" width="60" height="60" alt="Patrick Oyarzun"></a>
		</div>
		
	</header>


	<main role="main">
		<article itemscope itemtype="http://schema.org/BlogPosting">
			<h1 class="entry-title" itemprop="headline">Benchmarking (Benchmarking Elm Functions)</h1>
			<span class="entry-meta"><time itemprop="datePublished" datetime="2016-10-26">October 26, 2016</time></span>
			<section itemprop="entry-text">
				<p>In <a href="/blog/elm-bench/">my last post</a>, I released a benchmarking package for elm. I got some interesting feedback on reddit
from user ianmackenzie. What if my benchmarking package is adding significant overhead to the things it&rsquo;s trying to benchmark?
I hadn&rsquo;t made any particular effort to make it fast, so this is a great opportunity to try. As a matter of fact, I can use my
benchmark package to benchmark the new implementation. Let&rsquo;s try it out.</p>

<p>Here&rsquo;s a complete demo app that uses the library to benchmark a new implementation of the <code>repeat</code> function.
It essentially tries to benchmark the function <code>\() -&gt; ()</code>, which is the simplest possible function I could think of.
With any luck, the performance of the benchmarking tool should dominate.</p>

<pre><code>module Bootstrap exposing (..)

import Bench
import Html
import Html.App as App
import Time
import Task
import Process


type alias Model =
    { benchmarks : List ( String, Bench.Timing ) }


type Msg
    = BenchmarkDone String Bench.Timing
    | Noop


testFunc : () -&gt; ()
testFunc () =
    ()


newRepeat : (() -&gt; b) -&gt; Int -&gt; ()
newRepeat f n =
    if n &lt;= 0 then
        ()
    else
        let
            _ =
                f ()
        in
            newRepeat f (n - 1)


main : Program Never
main =
    App.program
        { init =
            ( { benchmarks = [] }
            , Task.perform (\_ -&gt; Noop) (\_ -&gt; Noop) (Process.sleep (Time.millisecond * 1000))
            )
        , view = view
        , update = update
        , subscriptions = subscriptions
        }


view : Model -&gt; Html.Html Msg
view model =
    let
        viewTiming ( name, timing ) =
            Html.div []
                [ Html.h1 [] [ Html.text name ]
                , Html.text (toString timing)
                ]
    in
        Html.div [] ((Html.text &quot;Benchmarks will appear here:&quot;) :: (List.map viewTiming model.benchmarks))


update : Msg -&gt; Model -&gt; ( Model, Cmd Msg )
update msg model =
    case msg of
        BenchmarkDone name timing -&gt;
            ( { model | benchmarks = ( name, timing ) :: model.benchmarks }, Cmd.none )

        Noop -&gt;
            ( model
            , Cmd.batch
                [ Bench.benchmark (BenchmarkDone &quot;Current Implementation&quot;) (Bench.repeat testFunc)
                , Bench.benchmark (BenchmarkDone &quot;Proposed Implementation&quot;) (newRepeat testFunc)
                ]
            )


subscriptions : Model -&gt; Sub Msg
subscriptions model =
    Sub.none

</code></pre>

<p>If you run this app (and make sure to pin the version of elm-bench at 1.0.0), you should see that the
proposed implementation is around an order of magnitude faster! You can also check out the <a href="/apps/benchception">live demo</a>. As of now, the new implementation has
been merged in as the default. I&rsquo;ve also added the benchmarking app as a sub module so you can easily
run small tests like this one. The <a href="http://package.elm-lang.org/packages/Logiraptor/elm-bench/latest">documentation is available on package.elm-lang.org</a></p>

<p>Thanks for reading!</p>

			</section>
		</article>
	</main>


	<footer role="contentinfo">
		<div class="hr"></div>
		<div class="footer-link">
			<a href="mailto:patrickoyarzun@gmail.com" target="_blank">Email</a>
			<a href="https://twitter.com/PatrickOyarzun" target="_blank">Twitter</a>
			
			<a href="https://github.com/Logiraptor/" target="_blank">GitHub</a>
		</div>
		<div class="copyright">Copyright &copy; Patrick Oyarzun All rights reserved.</div>
	</footer>

</div>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-86222328-1', 'auto');
	ga('send', 'pageview');
</script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

</body>
</html>
